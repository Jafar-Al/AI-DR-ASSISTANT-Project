{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, Input, Add, GlobalAveragePooling2D, Attention\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, f1_score,\n",
    "                           precision_recall_curve, roc_curve, roc_auc_score,\n",
    "                           average_precision_score, cohen_kappa_score,\n",
    "                           matthews_corrcoef, balanced_accuracy_score,\n",
    "                           jaccard_score, hamming_loss, recall_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f597fe",
   "metadata": {},
   "source": [
    "# **Run it in the last**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\path\\to\\your\\data.csv\"\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 1\n",
    "\n",
    "BATCHSIZE = 256\n",
    "EPOCHS = 200\n",
    "subset = float(input(\"Subset (e.g., 0.05 for 5%) [default=1]: \") or 1)\n",
    "train_ratio = float(input(\"Train split (e.g., 0.8) [default=0.8]: \") or 0.8)\n",
    "\n",
    "model, history, X_test, y_test = train_model_from_csv(csv_path, total_subset=subset, train_size=train_ratio)\n",
    "plot_training_history(history)\n",
    "metrics = evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = df[\"label\"].values\n",
    "    features = df.drop(columns=[\"label\"]).values\n",
    "    # Normalize and reshape into 2D images\n",
    "    features = features.astype(\"float32\") / 255.0\n",
    "    features = features.reshape(-1, HEIGHT, WIDTH, CHANNELS)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n=== Detailed classification report ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f'PR curve (AP = {average_precision:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('pr_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'precision': average_precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc,\n",
    "        'average_precision': average_precision,\n",
    "        'kappa': cohen_kappa_score(y_test, y_pred),\n",
    "        'mcc': matthews_corrcoef(y_test, y_pred),\n",
    "        'jaccard': jaccard_score(y_test, y_pred),\n",
    "        'hamming_loss': hamming_loss(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== All metrics ===\")\n",
    "    print(f\"Balanced Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"Average Precision: {metrics['average_precision']:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {metrics['mcc']:.4f}\")\n",
    "    print(f\"Jaccard Score: {metrics['jaccard']:.4f}\")\n",
    "    print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc56a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x, filters):\n",
    "    # Self-attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Add()([x, attention])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224,1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "  # Block 1\n",
    "    x = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "  \n",
    "  # Block 2\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "  \n",
    "  # Block 3\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "  \n",
    "  # Optional: Attention here\n",
    "  # x = attention_block(x, 128)\n",
    "  \n",
    "  # Block 4\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "  \n",
    "  # Head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_from_csv(csv_path, total_subset=1, train_size=0.8, test_size=0.2):\n",
    "    if train_size + test_size != 1.0:\n",
    "        raise ValueError(\"train_size and test_size must sum to 1 when not using validation.\")\n",
    "    \n",
    "    images, labels = load_data_csv(csv_path)\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "\n",
    "    # Subset\n",
    "    subset_size = int(len(images) * total_subset)\n",
    "    images, labels = images[:subset_size], labels[:subset_size]\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    model = create_model(input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00005, clipnorm=1.0),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.Precision(), \n",
    "                 tf.keras.metrics.Recall(), \n",
    "                 tf.keras.metrics.F1Score()]\n",
    "    )\n",
    "\n",
    "    def lr_schedule(epoch):\n",
    "        if epoch < 50:\n",
    "            return 0.00005\n",
    "        elif epoch < 100:\n",
    "            return 0.00001\n",
    "        else:\n",
    "            return 0.000005\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        LearningRateScheduler(lr_schedule)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCHSIZE,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    return model, history, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
