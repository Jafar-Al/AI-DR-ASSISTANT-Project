{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, Input, Add, GlobalAveragePooling2D, Attention\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, f1_score,\n",
    "                             precision_recall_curve, roc_curve, roc_auc_score,\n",
    "                             average_precision_score, cohen_kappa_score,\n",
    "                             matthews_corrcoef, balanced_accuracy_score,\n",
    "                             jaccard_score, hamming_loss, recall_score, precision_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\User\\OneDrive - University Of Jordan\\Desktop\\DR3\\AI-DR-ASSISTANT-Project\\CopiedFirst1000Rows.csv\" # Ensure this file is in the correct path\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 1\n",
    "\n",
    "# User inputs for configuration\n",
    "BATCHSIZE = int(input(\"BATCHSIZE (e.g., 64) [default=256]: \") or 256)\n",
    "EPOCHS = int(input(\"EPOCHS (e.g., 1024) [default=16]: \") or 16)\n",
    "subset_percentage = float(input(\"Subset for training (e.g., 0.05 for 5%) [default=1 for 100%]: \") or 1.0)\n",
    "train_ratio_config = float(input(\"Train split ratio (e.g., 0.8 for 80% train) [default=0.8]: \") or 0.8)\n",
    "test_ratio_config = 1.0 - train_ratio_config\n",
    "\n",
    "print(f\"Configuration: BATCHSIZE={BATCHSIZE}, EPOCHS={EPOCHS}, Subset={subset_percentage*100}%, TrainRatio={train_ratio_config}, TestRatio={test_ratio_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96664086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Image Dimensions (derived from 'pixel 0 to 16383 pixel' which is 16384 pixels) ---\n",
    "# Assuming 16384 pixels corresponds to a 128x128 grayscale image.\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 1\n",
    "\n",
    "# --- Inlined data loading and preprocessing logic ---\n",
    "print(\"Starting data loading and preprocessing...\")\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded CSV: {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: CSV file not found at '{csv_path}'. Please ensure the path is correct.\")\n",
    "    raise\n",
    "\n",
    "# 1. Labels: Multi-class Encoding excluding \"No Finding\"\n",
    "if \"Finding_Labels\" in df.columns:\n",
    "    # Remove rows where Finding_Labels is exactly \"No Finding\"\n",
    "    df = df[df['Finding_Labels'].str.strip() != \"No Finding\"].reset_index(drop=True)\n",
    "    \n",
    "    # Get unique labels after removing \"No Finding\"\n",
    "    unique_labels = df['Finding_Labels'].str.strip().unique()\n",
    "    print(f\"Unique labels after removing 'No Finding' ({len(unique_labels)}): {unique_labels}\")\n",
    "\n",
    "    # Create a mapping from label to integer index\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Map Finding_Labels to integer classes\n",
    "    df['MultiClass_Label'] = df['Finding_Labels'].str.strip().map(label_to_index)\n",
    "\n",
    "    labels_processed = df['MultiClass_Label'].values.reshape(-1, 1)  # Reshape to 2D array\n",
    "\n",
    "    print(f\"Processed labels into multi-class format excluding 'No Finding'.\")\n",
    "    print(f\"Label to index mapping: {label_to_index}\")\n",
    "    print(\"\\nExamples of 'MultiClass_Label' column:\")\n",
    "    print(df[['Finding_Labels', 'MultiClass_Label']].head(10))\n",
    "\n",
    "else:\n",
    "    labels_processed = None\n",
    "    print(\"ERROR: 'Finding_Labels' column not found.\")\n",
    "    raise ValueError(\"'Finding_Labels' column not found.\")\n",
    "\n",
    "\n",
    "# 2. Features: Initial drop of non-feature/target columns\n",
    "# Also drop the original 'Finding_Labels' as we created 'Binary_Finding_Label'\n",
    "columns_to_drop_for_features = [\"PatientID\", \"Original_Image_Index\", \"Finding_Labels\"]\n",
    "feature_df = df.drop(columns=[col for col in columns_to_drop_for_features if col in df.columns])\n",
    "print(f\"Dropped ID/target columns. Remaining feature columns: {feature_df.columns.tolist()}\")\n",
    "\n",
    "# 3. Encoding\n",
    "if \"Patient_Gender\" in feature_df.columns:\n",
    "    gender_map = {'M': 0, 'F': 1, 'O': 2} # O for Other/Unknown, map to a number\n",
    "    feature_df[\"Patient_Gender\"] = feature_df[\"Patient_Gender\"].map(gender_map).astype(\"float32\")\n",
    "    if feature_df[\"Patient_Gender\"].isnull().any():\n",
    "        print(f\"Warning: Null values in Patient_Gender after mapping. Filled with -1 (representing unknown).\")\n",
    "        feature_df[\"Patient_Gender\"] = feature_df[\"Patient_Gender\"].fillna(-1) # Fill NaNs created by unmapped values\n",
    "    print(\"Processed Patient_Gender.\")\n",
    "\n",
    "if \"View_Position\" in feature_df.columns:\n",
    "    # Ensure View_Position is treated as categorical (string type)\n",
    "    feature_df[\"View_Position\"] = feature_df[\"View_Position\"].astype(str)\n",
    "    view_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\") # handle_unknown='ignore' will create all-zero rows for unknown values\n",
    "    view_encoded = view_encoder.fit_transform(feature_df[[\"View_Position\"]])\n",
    "    view_df = pd.DataFrame(view_encoded, columns=view_encoder.get_feature_names_out([\"View_Position\"]), index=feature_df.index)\n",
    "    feature_df = pd.concat([feature_df.drop(columns=[\"View_Position\"]), view_df], axis=1)\n",
    "    print(f\"Processed View_Position (OneHotEncoded). New columns: {view_df.columns.tolist()}\")\n",
    "\n",
    "# 4. Standardization\n",
    "if \"Patient_Age\" in feature_df.columns:\n",
    "    # Ensure Patient_Age is numeric, coerce errors to NaN, then fill\n",
    "    feature_df[\"Patient_Age\"] = pd.to_numeric(feature_df[\"Patient_Age\"], errors='coerce')\n",
    "    if feature_df[\"Patient_Age\"].isnull().any():\n",
    "        median_age = feature_df[\"Patient_Age\"].median() # Or mean, or a specific value\n",
    "        print(f\"Warning: Null values in Patient_Age. Filled with median age: {median_age}.\")\n",
    "        feature_df[\"Patient_Age\"] = feature_df[\"Patient_Age\"].fillna(median_age)\n",
    "    \n",
    "    age_scaler = StandardScaler()\n",
    "    feature_df[\"Patient_Age\"] = age_scaler.fit_transform(feature_df[[\"Patient_Age\"]].astype(\"float32\"))\n",
    "    print(\"Processed Patient_Age (Standardized).\")\n",
    "\n",
    "# 5. Normalization (MinMax to [0,1] for specified metadata columns)\n",
    "metadata_cols_to_normalize = [\n",
    "    \"OriginalImage_Width\", \"OriginalImage_Height\",\n",
    "    \"OriginalImagePixelSpacing_x\", \"OriginalImagePixelSpacing_y\"\n",
    "]\n",
    "cols_present_for_norm = [col for col in metadata_cols_to_normalize if col in feature_df.columns]\n",
    "if cols_present_for_norm:\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    try:\n",
    "        # Ensure columns are numeric and fill NaNs before scaling\n",
    "        for col in cols_present_for_norm:\n",
    "            feature_df[col] = pd.to_numeric(feature_df[col], errors='coerce')\n",
    "            if feature_df[col].isnull().any():\n",
    "                print(f\"Warning: Null values in {col} before MinMax scaling. Filled with 0.\") # Or median/mean\n",
    "                feature_df[col] = feature_df[col].fillna(0) # Example: fill with 0\n",
    "        \n",
    "        feature_df[cols_present_for_norm] = feature_df[cols_present_for_norm].astype(\"float32\")\n",
    "        feature_df[cols_present_for_norm] = min_max_scaler.fit_transform(feature_df[cols_present_for_norm])\n",
    "        print(f\"Normalized metadata columns: {cols_present_for_norm}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during metadata normalization for {cols_present_for_norm}: {e}\")\n",
    "\n",
    "# 6. Pixel Data Handling\n",
    "# Based on 'pixel 0 to 16383 pixel', the columns are named 'pixel 0', 'pixel 1', etc.\n",
    "pixel_col_names = [f'pixel_{i}' for i in range(HEIGHT * WIDTH)]\n",
    "pixel_cols = [col for col in pixel_col_names if col in feature_df.columns]\n",
    "print(f\"Found {len(pixel_cols)} pixel columns.\")\n",
    "\n",
    "features_image_processed = None\n",
    "features_tabular_processed = None # Will hold non-pixel features\n",
    "\n",
    "if pixel_cols:\n",
    "    # Determine max_pixel_value from your data's bit depth (e.g., 255 for 8-bit, 16383 for 14-bit)\n",
    "    # The user mentioned 'pixel 0 to 16383 pixel' which implies 14-bit data, so max value is 16383.\n",
    "    # If your pixels are 0-255, change this to 255.0\n",
    "    max_pixel_value = 16383.0 # IMPORTANT: Set this to the actual max value of your pixel data\n",
    "\n",
    "    try:\n",
    "        # Ensure pixel columns are numeric and fill NaNs (e.g., with 0) before division\n",
    "        for p_col in pixel_cols:\n",
    "            feature_df[p_col] = pd.to_numeric(feature_df[p_col], errors='coerce').fillna(0)\n",
    "\n",
    "        feature_df[pixel_cols] = feature_df[pixel_cols].astype(\"float32\") / max_pixel_value\n",
    "        image_data_flat = feature_df[pixel_cols].values\n",
    "        \n",
    "        print(f'Min-max scaled pixel data shape: {image_data_flat.shape}')\n",
    "        print(f\"Pixel data min: {image_data_flat.min()}, max: {image_data_flat.max()}\") \n",
    "        print(f\"Max pixel value set to: {max_pixel_value}\")\n",
    "        \n",
    "        expected_pixels_count = HEIGHT * WIDTH * CHANNELS\n",
    "        if image_data_flat.shape[1] == expected_pixels_count:\n",
    "            features_image_processed = image_data_flat.reshape(-1, HEIGHT, WIDTH, CHANNELS)\n",
    "            print(f\"Reshaped pixel data to: {features_image_processed.shape}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Number of pixel columns ({image_data_flat.shape[1]}) does not match HEIGHT*WIDTH*CHANNELS ({expected_pixels_count}). Cannot reshape image data.\")\n",
    "            raise ValueError(\"Pixel data shape mismatch. Check HEIGHT, WIDTH, CHANNELS, and pixel column count.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during pixel data processing: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Identify and process remaining tabular features\n",
    "    tabular_feature_names = [col for col in feature_df.columns if col not in pixel_cols and col != 'Binary_Finding_Label']\n",
    "    if tabular_feature_names:\n",
    "        # Ensure remaining tabular features are numeric, fill NaNs\n",
    "        for tab_col in tabular_feature_names:\n",
    "            feature_df[tab_col] = pd.to_numeric(feature_df[tab_col], errors='coerce')\n",
    "            if feature_df[tab_col].isnull().any():\n",
    "                print(f\"Warning: Null values in tabular column {tab_col}. Filled with 0.\")\n",
    "                feature_df[tab_col] = feature_df[tab_col].fillna(0)\n",
    "        features_tabular_processed = feature_df[tabular_feature_names].values.astype(\"float32\")\n",
    "        print(f\"Processed tabular features: {features_tabular_processed.shape if features_tabular_processed is not None else 'None'}\")\n",
    "    else: # No other columns left for tabular data\n",
    "        features_tabular_processed = np.array([]).reshape(len(feature_df),0) # Empty array with correct number of samples\n",
    "        print(\"No additional tabular features found besides pixel data.\")\n",
    "        \n",
    "else: # No pixel columns found\n",
    "    print(\"Warning: No pixel columns found. The model expects image data.\")\n",
    "    # If only tabular data is found, this script will likely fail at model creation/training unless the model is adapted.\n",
    "    # For now, we assume image data is essential.\n",
    "    raise ValueError(\"No pixel columns found. Image data is required for the CNN model.\")\n",
    "\n",
    "if features_image_processed is None:\n",
    "    raise ValueError(\"Image features (pixel_cols) are missing or failed to process, but the model expects them.\")\n",
    "\n",
    "if len(features_image_processed) != len(labels_processed):\n",
    "    raise ValueError(f\"Inconsistent number of samples between processed images ({len(features_image_processed)}) and labels ({len(labels_processed)}).\")\n",
    "\n",
    "# Final processed data for the next steps:\n",
    "images_np_array = features_image_processed\n",
    "# tabular_np_array = features_tabular_processed # Keep this if you plan to use a multi-modal model\n",
    "\n",
    "print(f\"\\nData loading and preprocessing complete.\")\n",
    "print(f\"Image data shape: {images_np_array.shape}\")\n",
    "print(f\"Labels shape: {labels_processed.shape}\")\n",
    "if features_tabular_processed.shape[1] > 0:\n",
    "    print(f\"Tabular data shape: {features_tabular_processed.shape}\")\n",
    "\n",
    "# You can now proceed with splitting your data into training/validation/test sets\n",
    "# and feeding `images_np_array` and `labels_processed` (and optionally `features_tabular_processed`)\n",
    "# to your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined data shuffling, subsetting, and splitting ---\n",
    "print(\"Starting data shuffling, subsetting, and splitting...\")\n",
    "\n",
    "if not hasattr(images_np_array, 'shape') or not hasattr(labels_processed, 'shape'):\n",
    "     raise ValueError(\"Images or labels are not NumPy-like arrays after processing.\")\n",
    "if len(images_np_array) == 0:\n",
    "    raise ValueError(\"Features (images) are empty after processing, cannot proceed.\")\n",
    "\n",
    "images_shuffled, labels_shuffled = shuffle(images_np_array, labels_processed, random_state=42)\n",
    "print(\"Shuffled data.\")\n",
    "\n",
    "# Subset\n",
    "if not (0.0 < subset_percentage <= 1.0):\n",
    "    raise ValueError(\"subset_percentage must be between 0 (exclusive) and 1 (inclusive).\")\n",
    "num_total_samples = len(images_shuffled)\n",
    "subset_size = int(num_total_samples * subset_percentage)\n",
    "\n",
    "if subset_size == 0:\n",
    "    if num_total_samples == 0:\n",
    "         raise ValueError(\"No data available before applying subset.\")\n",
    "    else: # subset_percentage made it zero\n",
    "         print(f\"Warning: Subset size calculated as 0 with subset_percentage={subset_percentage}. Using 1 sample if available, or all if less than 1/percentage.\")\n",
    "         subset_size = 1 # Try to use at least one sample\n",
    "if subset_size > num_total_samples : subset_size = num_total_samples # Should not happen if percentage <= 1\n",
    "\n",
    "images_subset = images_shuffled[:subset_size]\n",
    "labels_subset = labels_shuffled[:subset_size]\n",
    "print(f\"Applied subset: {len(images_subset)} samples selected for training/testing.\")\n",
    "\n",
    "if len(images_subset) == 0:\n",
    "    raise ValueError(\"After applying subset, no data remains. Check subset_percentage and original data size.\")\n",
    "\n",
    "# Stratification logic (attempt)\n",
    "stratify_option = None\n",
    "if labels_subset is not None and labels_subset.shape[0] > 1 and test_ratio_config > 0 and test_ratio_config < 1:\n",
    "    min_samples_per_class_for_split = max(2, int(np.ceil(1/test_ratio_config)), int(np.ceil(1/(1-test_ratio_config))))\n",
    "\n",
    "    if labels_subset.ndim == 2 and labels_subset.shape[1] > 0:  # Multi-label binarized\n",
    "        try:\n",
    "            # For multi-label, stratify by unique combinations of labels\n",
    "            unique_rows, counts_of_unique_rows = np.unique(labels_subset, axis=0, return_counts=True)\n",
    "            if len(unique_rows) > 1 and np.all(counts_of_unique_rows >= min_samples_per_class_for_split):\n",
    "                stratify_option = labels_subset # Use the full label vectors for stratification\n",
    "                print(f\"Stratification enabled for multi-label. Min samples for a unique label combination: {np.min(counts_of_unique_rows)}.\")\n",
    "            else:\n",
    "                print(f\"Warning: Stratification disabled for multi-label. Conditions not met. Smallest unique group has {np.min(counts_of_unique_rows) if len(counts_of_unique_rows)>0 else 'N/A'} samples (need >={min_samples_per_class_for_split}), or only {len(unique_rows)} unique combinations.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error during stratification check for multi-label: {e}. Stratification disabled.\")\n",
    "    elif labels_subset.ndim == 1:  # Single-label case\n",
    "        unique_labels, counts_of_unique_labels = np.unique(labels_subset, return_counts=True)\n",
    "        if len(unique_labels) > 1 and np.all(counts_of_unique_labels >= min_samples_per_class_for_split):\n",
    "            stratify_option = labels_subset\n",
    "            print(f\"Stratification enabled for single-label. Min samples for a class: {np.min(counts_of_unique_labels)}.\")\n",
    "        else:\n",
    "            print(f\"Warning: Stratification disabled for single-label. Conditions not met. Smallest class has {np.min(counts_of_unique_labels) if len(counts_of_unique_labels)>0 else 'N/A'} samples (need >={min_samples_per_class_for_split}), or only {len(unique_labels)} classes.\")\n",
    "else:\n",
    "    print(\"Stratification not applicable (e.g., no test set, or not enough data).\")\n",
    "\n",
    "\n",
    "# Split data\n",
    "if test_ratio_config == 0: # Use all subset data for training\n",
    "    X_train, y_train = images_subset, labels_subset\n",
    "    X_test, y_test = np.array([]).reshape(0, *images_subset.shape[1:]), np.array([]).reshape(0, *labels_subset.shape[1:])\n",
    "    print(\"Using all subset data for training. No test set created from split.\")\n",
    "elif test_ratio_config == 1: # Use all subset data for testing\n",
    "    X_test, y_test = images_subset, labels_subset\n",
    "    X_train, y_train = np.array([]).reshape(0, *images_subset.shape[1:]), np.array([]).reshape(0, *labels_subset.shape[1:])\n",
    "    print(\"Using all subset data for testing. No training set created from split.\")\n",
    "else: # Split into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images_subset, labels_subset, test_size=test_ratio_config, random_state=42,\n",
    "        stratify=stratify_option\n",
    "    )\n",
    "print(f\"Data split: Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "if len(X_train) == 0 and EPOCHS > 0: # If no training data but epochs are set, it's an issue.\n",
    "    raise ValueError(\"No training samples available after split, but EPOCHS > 0. Cannot train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined model definition ---\n",
    "print(\"Defining the CNN model...\")\n",
    "\n",
    "# Determine num_classes for model output layer based on y_train or y_test (if y_train is empty)\n",
    "if len(y_train) > 0:\n",
    "    num_classes_model = y_train.shape[1] if y_train.ndim == 2 else 1\n",
    "elif len(y_test) > 0: # If training set is empty but test set exists (e.g. test_ratio_config = 1)\n",
    "    num_classes_model = y_test.shape[1] if y_test.ndim == 2 else 1\n",
    "elif len(labels_subset) > 0: # Fallback to labels_subset if y_train/y_test are empty from split\n",
    "     num_classes_model = labels_subset.shape[1] if labels_subset.ndim == 2 else 1\n",
    "else: # Fallback to the originally processed labels if all else fails\n",
    "     num_classes_model = labels_processed.shape[1] if labels_processed.ndim == 2 else 1\n",
    "print(f\"Model will have {num_classes_model} output neuron(s).\")\n",
    "\n",
    "model_input_shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "inputs = Input(shape=model_input_shape)\n",
    "\n",
    "# Convolutional Block 1\n",
    "x = Conv2D(32, (3, 3), padding='same', name='conv1_1')(inputs)\n",
    "x = BatchNormalization(name='bn1_1')(x)\n",
    "x = tf.keras.layers.ReLU(name='relu1_1')(x)\n",
    "x = MaxPooling2D((2, 2), name='pool1')(x)\n",
    "\n",
    "# Convolutional Block 2\n",
    "x = Conv2D(64, (3, 3), padding='same', name='conv2_1')(x)\n",
    "x = BatchNormalization(name='bn2_1')(x)\n",
    "x = tf.keras.layers.ReLU(name='relu2_1')(x)\n",
    "x = MaxPooling2D((2, 2), name='pool2')(x)\n",
    "\n",
    "# Convolutional Block 3\n",
    "x = Conv2D(128, (3, 3), padding='same', name='conv3_1')(x)\n",
    "x = BatchNormalization(name='bn3_1')(x)\n",
    "x = tf.keras.layers.ReLU(name='relu3_1')(x)\n",
    "x = MaxPooling2D((2, 2), name='pool3')(x)\n",
    "\n",
    "# Attention Block (Optional, currently not used in original create_model_dynamic)\n",
    "# If you want to use an attention mechanism, you could insert it here.\n",
    "# For example:\n",
    "# att_filters = 128\n",
    "# attention_output = Attention()([x, x]) # Self-attention\n",
    "# x = Add()([x, attention_output])\n",
    "# x = Conv2D(att_filters, (1,1), padding='same', activation='relu')(x) # Optional: further processing\n",
    "\n",
    "# Convolutional Block 4\n",
    "x = Conv2D(256, (3, 3), padding='same', name='conv4_1')(x)\n",
    "x = BatchNormalization(name='bn4_1')(x)\n",
    "x = tf.keras.layers.ReLU(name='relu4_1')(x)\n",
    "x = MaxPooling2D((2, 2), name='pool4')(x)\n",
    "\n",
    "# Head\n",
    "x = GlobalAveragePooling2D(name='gap')(x)\n",
    "x = Dropout(0.5, name='dropout_head1')(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_head1')(x)\n",
    "x = Dropout(0.3, name='dropout_head2')(x)\n",
    "\n",
    "# Output Layer\n",
    "if num_classes_model == 1: # Binary classification\n",
    "    output_layer = Dense(1, activation='sigmoid', name='output_binary')(x)\n",
    "else: # Multi-label classification\n",
    "    output_layer = Dense(num_classes_model, activation='sigmoid', name='output_multilabel')(x)\n",
    "\n",
    "model = Model(inputs, output_layer, name='Chest_XRay_CNN')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined model compilation and training ---\n",
    "print(\"Compiling the model...\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00005, clipnorm=1.0),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), # Good for both binary and multi-label with sigmoid\n",
    "    metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Precision(name='precision'), \n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=(num_classes_model > 1), num_labels=num_classes_model if num_classes_model > 1 and num_classes_model is not None else None)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "def lr_schedule(epoch, lr): # lr argument is passed by callback\n",
    "    if epoch < 50:\n",
    "        return 0.00005\n",
    "    elif epoch < 100:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000005\n",
    "\n",
    "# Callbacks\n",
    "# Adjust monitor metrics if no validation data\n",
    "val_monitor_metric_acc = 'val_accuracy'\n",
    "val_monitor_metric_loss = 'val_loss'\n",
    "\n",
    "if len(X_test) == 0 or len(y_test) == 0: # No validation data\n",
    "    print(\"Warning: No validation data available for training. Callbacks will monitor training metrics if applicable.\")\n",
    "    val_monitor_metric_acc = 'accuracy' # Monitor training accuracy instead\n",
    "    val_monitor_metric_loss = 'loss'   # Monitor training loss instead\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint('best_model.h5', monitor=val_monitor_metric_acc, save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor=val_monitor_metric_loss, patience=25, restore_best_weights=True, verbose=1),\n",
    "    LearningRateScheduler(lr_schedule)\n",
    "]\n",
    "\n",
    "# Training\n",
    "history = None\n",
    "if len(X_train) > 0 and EPOCHS > 0:\n",
    "    print(f\"Starting model training for {EPOCHS} epochs with batch size {BATCHSIZE}...\")\n",
    "    validation_data_fit = (X_test, y_test) if len(X_test) > 0 and len(y_test) > 0 else None\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCHSIZE,\n",
    "        validation_data=validation_data_fit,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model training finished.\")\n",
    "elif EPOCHS == 0:\n",
    "    print(\"EPOCHS is 0. Skipping model training.\")\n",
    "else: # len(X_train) == 0\n",
    "    print(\"No training data (X_train is empty). Skipping model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Directory Configuration for Evaluation Outputs ---\n",
    "# IMPORTANT: Define MAIN_EXPERIMENT_DIR, ideally in an earlier configuration cell (e.g., Cell 2)\n",
    "# User-defined base directory for all outputs of this specific experiment run\n",
    "MAIN_EXPERIMENT_DIR = \"Output\"  # <--- CHANGE THIS to your desired main output folder name\n",
    "\n",
    "# Generate a timestamp string for the subfolder name\n",
    "# This will create a unique folder for each run of this cell based on current date and time\n",
    "timestamp_str = datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm%Ss\") # e.g., \"2025-05-13_19h50m49s\"\n",
    "IMAGEPATH = 'AccLossPlots'\n",
    "os.makedirs(os.path.join(MAIN_EXPERIMENT_DIR, timestamp_str, IMAGEPATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined plotting of training history ---\n",
    "print(\"Plotting training history (if training was performed)...\")\n",
    "if history is not None and history.history:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'accuracy' in history.history:\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "                plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    if 'accuracy' in history.history or 'val_accuracy' in history.history:\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No accuracy data to plot.', ha='center', va='center')\n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "    plt.savefig(os.path.join(MAIN_EXPERIMENT_DIR, timestamp_str, IMAGEPATH,'accuracy_history.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(\"Training history plots saved to 'training_history.png'\")\n",
    "else:\n",
    "    print(\"Skipping plotting training history: No history object available or history is empty (training likely not performed or failed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed91466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined plotting of training history ---\n",
    "print(\"Plotting training history (if training was performed)...\")\n",
    "if history is not None and history.history:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'loss' in history.history:\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss Over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "    if 'loss' in history.history or 'val_loss' in history.history:\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No loss data to plot.', ha='center', va='center')\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MAIN_EXPERIMENT_DIR, timestamp_str, IMAGEPATH, 'loss_history.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(\"Training history plots saved to 'training_history.png'\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping plotting training history: No history object available or history is empty (training likely not performed or failed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inlined model evaluation ---\n",
    "print(\"Evaluating model (if test data and model exist)...\")\n",
    "metrics_results = {}\n",
    "\n",
    "if 'model' in locals() and len(X_test) > 0 and len(y_test) > 0:   \n",
    "    # Dynamically create the subfolder name for evaluation plots using the timestamp\n",
    "    EVAL_PLOTS_SUBFOLDER_NAME_WITH_TIMESTAMP = f\"evaluation_plots\" \n",
    "    \n",
    "    # Construct the full path for evaluation plots\n",
    "    output_dir_for_this_cell = os.path.join(MAIN_EXPERIMENT_DIR, timestamp_str, EVAL_PLOTS_SUBFOLDER_NAME_WITH_TIMESTAMP)\n",
    "    \n",
    "    # Create the directory structure if it doesn't exist\n",
    "    os.makedirs(output_dir_for_this_cell, exist_ok=True) \n",
    "    print(f\"Evaluation plots from this cell will be saved to: {os.path.abspath(output_dir_for_this_cell)}\")\n",
    "    # --- End of Directory Configuration ---\n",
    "\n",
    "    print(f\"Evaluating model on {len(X_test)} test samples.\")\n",
    "    y_pred_proba_eval = model.predict(X_test)\n",
    "    y_pred_eval = (y_pred_proba_eval > 0.5).astype(int) # Thresholding probabilities to get binary predictions\n",
    "    \n",
    "    print(\"\\n=== Detailed Classification Report ===\")\n",
    "    target_names_report = None\n",
    "    if 'mlb' in locals() and hasattr(mlb, 'classes_'): # Check if mlb (MultiLabelBinarizer) is defined and was fit\n",
    "        target_names_report = mlb.classes_\n",
    "        \n",
    "    try:\n",
    "        # Ensure y_test and y_pred_eval have compatible shapes for classification_report\n",
    "        print(classification_report(y_test, y_pred_eval, target_names=target_names_report, zero_division=0))\n",
    "    except ValueError as e_report:\n",
    "        print(f\"Could not generate classification report: {e_report}. Check shapes: y_test {y_test.shape}, y_pred_eval {y_pred_eval.shape}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"\\nGenerating Confusion Matrices...\")\n",
    "    if num_classes_model == 1: # Binary case\n",
    "        try:\n",
    "            cm_eval = confusion_matrix(y_test.ravel(), y_pred_eval.ravel()) \n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.heatmap(cm_eval, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Confusion Matrix (Binary)')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            base_file_name_cm_binary = 'confusion_matrix_binary.png'\n",
    "            full_save_path_cm_binary = os.path.join(output_dir_for_this_cell, base_file_name_cm_binary)\n",
    "            plt.savefig(full_save_path_cm_binary)\n",
    "            print(f\"Saved plot to '{full_save_path_cm_binary}'\")\n",
    "            plt.close()\n",
    "        except ValueError as e_cm:\n",
    "            print(f\"Could not generate binary confusion matrix: {e_cm}\")\n",
    "    else: # Multi-label case\n",
    "        for i in range(num_classes_model):\n",
    "            label_name = target_names_report[i] if target_names_report is not None and i < len(target_names_report) else f\"Label_{i+1}\"\n",
    "            try:\n",
    "                cm_label = confusion_matrix(y_test[:, i], y_pred_eval[:, i])\n",
    "                plt.figure(figsize=(5, 3.5)) \n",
    "                sns.heatmap(cm_label, annot=True, fmt='d', cmap='Blues')\n",
    "                plt.title(f'CM for: {label_name}')\n",
    "                plt.ylabel('True')\n",
    "                plt.xlabel('Predicted')\n",
    "                base_file_name_cm_multi = f'confusion_matrix_{label_name.replace(\" \",\"_\").replace(\"/\",\"_\")}.png' \n",
    "                full_save_path_cm_multi = os.path.join(output_dir_for_this_cell, base_file_name_cm_multi)\n",
    "                plt.savefig(full_save_path_cm_multi)\n",
    "                print(f\"Saved plot to '{full_save_path_cm_multi}'\")\n",
    "                plt.close()\n",
    "            except Exception as e_cml:\n",
    "                 print(f\"Could not generate/save confusion matrix for label {label_name}: {e_cml}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    print(\"\\nGenerating ROC Curve...\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if num_classes_model == 1:\n",
    "        fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred_proba_eval.ravel())\n",
    "        roc_auc_val = roc_auc_score(y_test.ravel(), y_pred_proba_eval.ravel())\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_val:.3f})')\n",
    "    else: \n",
    "        fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred_proba_eval.ravel()) \n",
    "        roc_auc_val = roc_auc_score(y_test, y_pred_proba_eval, average='micro', multi_class='ovr') \n",
    "        plt.plot(fpr, tpr, label=f'Micro-average ROC (AUC = {roc_auc_val:.3f})')\n",
    "            \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    base_file_name_roc = 'roc_curve.png'\n",
    "    full_save_path_roc = os.path.join(output_dir_for_this_cell, base_file_name_roc)\n",
    "    plt.savefig(full_save_path_roc)\n",
    "    print(f\"Saved plot to '{full_save_path_roc}'\")\n",
    "    plt.close()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    print(\"\\nGenerating Precision-Recall Curve...\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if num_classes_model == 1:\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test.ravel(), y_pred_proba_eval.ravel())\n",
    "        average_precision_val = average_precision_score(y_test.ravel(), y_pred_proba_eval.ravel())\n",
    "        plt.plot(recall_vals, precision_vals, label=f'PR curve (AP = {average_precision_val:.3f})')\n",
    "    else: \n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test.ravel(), y_pred_proba_eval.ravel())\n",
    "        average_precision_val = average_precision_score(y_test, y_pred_proba_eval, average=\"micro\")\n",
    "        plt.plot(recall_vals, precision_vals, label=f'Micro-average PR (AP = {average_precision_val:.3f})')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"best\")\n",
    "    base_file_name_pr = 'pr_curve.png'\n",
    "    full_save_path_pr = os.path.join(output_dir_for_this_cell, base_file_name_pr)\n",
    "    plt.savefig(full_save_path_pr)\n",
    "    print(f\"Saved plot to '{full_save_path_pr}'\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate various scalar metrics\n",
    "    print(\"\\nCalculating Scalar Metrics...\")\n",
    "    try:\n",
    "      metrics_results['balanced_accuracy'] = balanced_accuracy_score(y_test, y_pred_eval)\n",
    "    except Exception as e: metrics_results['balanced_accuracy'] = f\"Error: {e}\"\n",
    "    metrics_results['precision_micro'] = precision_score(y_test, y_pred_eval, average='micro', zero_division=0)\n",
    "    metrics_results['recall_micro'] = recall_score(y_test, y_pred_eval, average='micro', zero_division=0)\n",
    "    metrics_results['f1_micro'] = f1_score(y_test, y_pred_eval, average='micro', zero_division=0)\n",
    "    \n",
    "    metrics_results['precision_macro'] = precision_score(y_test, y_pred_eval, average='macro', zero_division=0)\n",
    "    metrics_results['recall_macro'] = recall_score(y_test, y_pred_eval, average='macro', zero_division=0)\n",
    "    metrics_results['f1_macro'] = f1_score(y_test, y_pred_eval, average='macro', zero_division=0)\n",
    "    \n",
    "    if y_pred_proba_eval is not None:\n",
    "        try:\n",
    "            metrics_results['roc_auc_micro_calc'] = roc_auc_score(y_test, y_pred_proba_eval, average='micro', multi_class='ovr')\n",
    "            metrics_results['roc_auc_macro_calc'] = roc_auc_score(y_test, y_pred_proba_eval, average='macro', multi_class='ovr')\n",
    "        except ValueError as e_auc: \n",
    "            metrics_results['roc_auc_micro_calc'] = f\"Not defined ({e_auc})\"\n",
    "            metrics_results['roc_auc_macro_calc'] = f\"Not defined ({e_auc})\"\n",
    "\n",
    "        metrics_results['average_precision_micro_calc'] = average_precision_score(y_test, y_pred_proba_eval, average='micro')\n",
    "        metrics_results['average_precision_macro_calc'] = average_precision_score(y_test, y_pred_proba_eval, average='macro')\n",
    "            \n",
    "    if num_classes_model == 1: \n",
    "        try:\n",
    "            metrics_results['kappa'] = cohen_kappa_score(y_test.ravel(), y_pred_eval.ravel())\n",
    "            metrics_results['mcc'] = matthews_corrcoef(y_test.ravel(), y_pred_eval.ravel())\n",
    "        except Exception as e_kappa_mcc:\n",
    "             metrics_results['kappa'] = f\"Error: {e_kappa_mcc}\"\n",
    "             metrics_results['mcc'] = f\"Error: {e_kappa_mcc}\"\n",
    "\n",
    "    metrics_results['jaccard_micro'] = jaccard_score(y_test, y_pred_eval, average='micro', zero_division=0)\n",
    "    metrics_results['jaccard_macro'] = jaccard_score(y_test, y_pred_eval, average='macro', zero_division=0)\n",
    "    metrics_results['hamming_loss'] = hamming_loss(y_test, y_pred_eval)\n",
    "    \n",
    "    print(\"\\n=== Final Calculated Metrics Summary ===\")\n",
    "    for key, value in metrics_results.items():\n",
    "        if isinstance(value, (float, np.float64)): \n",
    "            print(f\"- {key.replace('_', ' ').capitalize()}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"- {key.replace('_', ' ').capitalize()}: {value}\")\n",
    "else:\n",
    "    print(\"Skipping model evaluation: Model not trained, or no test data (X_test or y_test is empty).\")\n",
    "\n",
    "print(\"\\n--- End of Script ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"lower right\") # 4 options: lower left, lower right, upper left, upper right\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper right\") # 4 options: lower left, lower right, upper left, upper right\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
